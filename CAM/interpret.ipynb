{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cde3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import click\n",
    "from click_option_group import optgroup\n",
    "import gc\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "bar_format = \"{percentage:3.0f}%|{bar:20}{r_bar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41502412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import CAM\n",
    "from jaspar import get_figure, reformat_motifs\n",
    "from sequence import one_hot_encode, rc_one_hot_encoding, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a52766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9254cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_file = \"../results/SMS.published/CAM/CTCF.NA@snappy-grey-markhor/best_model.pth.tar\"\n",
    "#training_file = \"../results/SMS.published/FASTA/Train/CTCF.NA@snappy-grey-markhor.fa.gz\"\n",
    "#output_dir = \"../results/SMS.published/CAM/CTCF.NA@snappy-grey-markhor/\"\n",
    "#tf_name = \"SOX2.NA\"\n",
    "#model_file = \"../results/Human-Mouse-Project/CAM/best_model.pth.tar\"\n",
    "#training_file = \"../results/Human-Mouse-Project/FASTA/train.fa.gz\"\n",
    "#output_dir = \"../results/Human-Mouse-Project/CAM/\"\n",
    "#tf_name = \"human-mouse\"\n",
    "model_file = \"../results/CHS/CAM/ZBED2.FL@hilly-bronze-frise/best_model.pth.tar\"\n",
    "training_file = \"../results/CHS/FASTA/Train/ZBED2.FL@hilly-bronze-frise.fa.gz\"\n",
    "output_dir = \"../results/CHS/CAM/ZBED2.FL@hilly-bronze-frise/\"\n",
    "tf_name = \"ZBED2.FL@hilly-bronze-frise\"\n",
    "batch_size = 2**6\n",
    "debugging = False\n",
    "threads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eba866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dirs\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for subdir in [\"sites\", \"motifs\", \"logos\"]:\n",
    "    if not os.path.isdir(os.path.join(output_dir, subdir)):\n",
    "        os.makedirs(os.path.join(output_dir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f23bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAM(\n",
       "  (linears): Sequential(\n",
       "    (0): Conv1d(64, 16, kernel_size=(19,), stride=(1,), padding=(19,), groups=16)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ExpAct()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): UnSqueeze()\n",
       "    (6): Conv1d(496, 1600, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (7): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.3, inplace=False)\n",
       "    (10): Conv1d(1600, 16, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (11): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (final): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "selene_dict = torch.load(model_file)\n",
    "model = CAM(\n",
    "    selene_dict[\"options\"][\"cnn_units\"],\n",
    "    selene_dict[\"options\"][\"kernel_size\"],\n",
    "    selene_dict[\"options\"][\"sequence_length\"],\n",
    "    selene_dict[\"options\"][\"n_features\"],\n",
    "    selene_dict[\"options\"][\"clamp_weights\"],\n",
    "    selene_dict[\"options\"][\"no_padding\"],\n",
    "    selene_dict[\"options\"][\"weights_file\"],\n",
    ")\n",
    "model.load_state_dict(selene_dict[\"state_dict\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13dfb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "if selene_dict[\"options\"][\"no_padding\"]:\n",
    "    padding = 0\n",
    "else:\n",
    "    padding = selene_dict[\"options\"][\"kernel_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe340ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Xs_ys_record_ids_sequences(fasta_file, debugging=False, reverse_complement=False):\n",
    "\n",
    "    # Initialize\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    record_ids = []\n",
    "    sequences = []\n",
    "\n",
    "    # Xs / ys\n",
    "    handle = __get_handle(fasta_file)\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        _, y_list = record.description.split()\n",
    "        Xs.append(one_hot_encode(str(record.seq).upper()))\n",
    "        ys.append([float(y) for y in y_list.split(\";\")])\n",
    "        record_ids.append((record.id, \"+\"))\n",
    "        sequences.append(str(record.seq))\n",
    "\n",
    "    # Reverse complement\n",
    "    if reverse_complement:\n",
    "        n = len(Xs)\n",
    "        for i in range(n):\n",
    "            Xs.append(rc_one_hot_encoding(Xs[i]))\n",
    "            ys.append(ys[i])\n",
    "            record_ids.append((record_ids[i][0], \"-\"))\n",
    "            sequences.append(rc(sequences[i]))\n",
    "\n",
    "    # Return 1,000 sequences\n",
    "    if debugging:\n",
    "        return(np.array(Xs)[:10000], np.array(ys)[:10000], \n",
    "               np.array(record_ids)[:10000])\n",
    "\n",
    "    return(np.array(Xs), np.array(ys), np.array(record_ids), sequences)\n",
    "\n",
    "def _get_data_loader(Xs_train, ys_train, batch_size=2**6, threads=1):\n",
    "\n",
    "    # TensorDatasets\n",
    "    train_set = TensorDataset(torch.Tensor(Xs_train), torch.Tensor(ys_train))\n",
    "\n",
    "    # DataLoaders\n",
    "    kwargs = dict(batch_size=batch_size, num_workers=threads)\n",
    "    train_loader = DataLoader(train_set, **kwargs)\n",
    "\n",
    "    return(train_loader)\n",
    "\n",
    "def __get_handle(file_name):\n",
    "    if file_name.endswith(\"gz\"):\n",
    "        handle = gzip.open(file_name, \"rt\")\n",
    "    else:\n",
    "        handle = open(file_name, \"rt\")\n",
    "    return(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4df12ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNNNNNNNNNNNNNNNNNNCGGCAGTCTcctccctccttccctccctccccgactccctccctcccgccttccctctccgctctcctccctccacccgctctccttccccctcccccctccGAACCCGGGCGCAAGGGGGGAATTAGAAACTGCTCTAGAAGGATTTTAAACAACTGGCTGTTCTCTCCGCCGCCACCCCTCCCCCCGCGCCGCCCGCGCNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNTACCGGACCCCACGGAGCAAGTTATTAACGTTGAGACTCGACGCCACTCTCCGCCAGAGCGCTTGCGTCCGGACTCTGACCAAGGGCCGGCCGCGGTACCCTCGGGGGAGAAAGCAACCTGTCGGCTGGTTTACTGCGTCTCACAGCCCCGACCTTCCAGAGGCTGCCCAAGGCGAAGGGGGTTGCCGTCGGTAAGGGTTTNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNGCCCCCGCTCGACCCCGCCGCGGCGACTAGCAAGCTGTGGCCGCCGGAAGCCACGCCCCCGGCGCCTGCCATGACGGAGTCGGGCAATTCCGGGTTCGTGACACTTTCCTCACACCGATCGCGACGGTGGATGGGCCGGCGGCCATCTTAGGTACTGGTAGAGCGACTCATTTCCGGAACGCGGTCTTGGGAGCCGGAAGANNNNNNNNNNNNNNNNNNN',\n",
       "       ...,\n",
       "       'NNNNNNNNNNNNNNNNNNNCACCAATCGACTGCACGAACTCCCACCACGCGTCAGAAAGCCTCTCTCACTTTTGGCGGCACGTCCACGCTCACCACACCGACAGCACTCACCGGGGGGCACGCTCACACACTGCACACACGGCACAGCTCGTACCACAGCACTGGTTTCTTCAGACAGCGATCTACGCCGCGCCAGTCTCTGGTTGCAACAGACACACCGNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNAGCCCCGCCCCCTTCTCGAACGCCAGCAATTTGACGTTCGGGTGTTCTCGGCTCGGCCGAATCCGTAGCCCCGCCTCCTCCCGGACGCAATAGGTTCGGCGTTCGGGCGTCATCGGCTCCCGGCAGCCTCGCGGCCTGTGGCCCCGCCCCCTCCGAGCGCCAGCGCACCCCAGTTGGGGAGTTCCCGCCCTACGACCGAACNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNGCACTGCCAGCTGTACCGCGGGGGAAGGGCGCGGGGGATATCAGTCCGCCGGGGCCATCCCCCCTCGTCGCAGGGCGCCCTGCTGCTTTATCGCAAGCGGTGTTCCAAGACCCAGCCCGAGGTTGAATAAAAAAATCTGGGCGGACACCGTGCGGCACTCCAAAGTCAACCCAGACCAGGACTGGGCGCCAACTTGAAGCGNNNNNNNNNNNNNNNNNNN'],\n",
       "      dtype='<U239')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Xs/ys/record ids\n",
    "Xs, ys, record_ids, sequences = _get_Xs_ys_record_ids_sequences(training_file, debugging, True)\n",
    "\n",
    "# Get DataLoader\n",
    "data_loader = _get_data_loader(list(Xs), list(ys), batch_size, threads)\n",
    "\n",
    "# Input data\n",
    "if np.unique(ys[:, 0]).size == 2:\n",
    "    input_data = \"binary\"\n",
    "else:\n",
    "    input_data = \"linear\"\n",
    "\n",
    "# Fix sequences\n",
    "for i in range(len(sequences)):\n",
    "    sequences[i] = \"N\" * padding + sequences[i] + \"N\" * padding\n",
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16930941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del Xs\n",
    "del ys\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15222d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [00:01<00:00, 166.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "# Get sequences, outputs, and labels\n",
    "with torch.no_grad():\n",
    "    for x, label in tqdm(data_loader, total=len(data_loader)):\n",
    "\n",
    "        # Get outputs\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        if input_data == \"binary\":\n",
    "            out = torch.sigmoid(out)\n",
    "        outputs.extend(out.detach().cpu().numpy())\n",
    "\n",
    "        # Get labels\n",
    "        labels.extend(label.numpy())\n",
    "\n",
    "# To NumPy\n",
    "outputs = np.array(outputs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d2c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_activations(model, data_loader, activations):\n",
    "\n",
    "    # Counter\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(data_loader, total=len(data_loader)):\n",
    "            x = x.to(device)\n",
    "            x = x.repeat(1, model._options[\"cnn_units\"], 1)\n",
    "            activations[idx:idx+x.shape[0], :, :] = model.linears[:3](x).cpu()\n",
    "            idx += x.shape[0]           \n",
    "\n",
    "    return(activations.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0511c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [00:01<00:00, 210.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[2.232 , 2.95  , 1.521 , ..., 2.31  , 1.852 , 2.232 ],\n",
       "        [1.536 , 1.451 , 0.943 , ..., 1.521 , 1.583 , 1.536 ],\n",
       "        [1.14  , 1.148 , 0.716 , ..., 1.301 , 0.918 , 1.14  ],\n",
       "        ...,\n",
       "        [0.8936, 1.15  , 1.162 , ..., 0.813 , 1.011 , 0.8936],\n",
       "        [1.015 , 1.302 , 1.834 , ..., 0.7437, 0.971 , 1.015 ],\n",
       "        [2.33  , 2.193 , 2.574 , ..., 1.92  , 1.842 , 2.33  ]],\n",
       "\n",
       "       [[2.232 , 2.455 , 1.312 , ..., 2.13  , 2.549 , 2.232 ],\n",
       "        [1.536 , 1.418 , 1.177 , ..., 1.637 , 1.624 , 1.536 ],\n",
       "        [1.14  , 0.953 , 0.869 , ..., 1.087 , 1.043 , 1.14  ],\n",
       "        ...,\n",
       "        [0.8936, 1.162 , 1.099 , ..., 1.006 , 1.1045, 0.8936],\n",
       "        [1.015 , 1.045 , 1.474 , ..., 0.682 , 0.8237, 1.015 ],\n",
       "        [2.33  , 1.955 , 2.475 , ..., 2.975 , 2.594 , 2.33  ]],\n",
       "\n",
       "       [[2.232 , 2.201 , 2.93  , ..., 3.074 , 2.127 , 2.232 ],\n",
       "        [1.536 , 1.1875, 2.04  , ..., 1.315 , 1.568 , 1.536 ],\n",
       "        [1.14  , 1.09  , 1.853 , ..., 1.467 , 1.186 , 1.14  ],\n",
       "        ...,\n",
       "        [0.8936, 1.123 , 1.201 , ..., 0.869 , 1.034 , 0.8936],\n",
       "        [1.015 , 1.316 , 1.223 , ..., 0.6904, 0.9497, 1.015 ],\n",
       "        [2.33  , 2.217 , 2.62  , ..., 1.918 , 2.486 , 2.33  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.186 , 2.87  , 1.029 , ..., 1.352 , 2.39  , 2.186 ],\n",
       "        [1.614 , 1.522 , 1.359 , ..., 1.704 , 1.6875, 1.614 ],\n",
       "        [1.155 , 1.164 , 0.7134, ..., 1.146 , 1.268 , 1.155 ],\n",
       "        ...,\n",
       "        [0.8843, 1.139 , 1.118 , ..., 0.828 , 1.04  , 0.8843],\n",
       "        [1.027 , 1.322 , 1.749 , ..., 0.9575, 0.9126, 1.027 ],\n",
       "        [2.38  , 2.242 , 3.55  , ..., 2.11  , 1.711 , 2.38  ]],\n",
       "\n",
       "       [[2.186 , 1.478 , 1.946 , ..., 1.97  , 1.82  , 2.186 ],\n",
       "        [1.614 , 1.727 , 1.511 , ..., 1.5625, 1.665 , 1.614 ],\n",
       "        [1.155 , 1.086 , 1.099 , ..., 1.25  , 0.9307, 1.155 ],\n",
       "        ...,\n",
       "        [0.8843, 1.081 , 1.168 , ..., 0.792 , 1.    , 0.8843],\n",
       "        [1.027 , 1.249 , 1.13  , ..., 0.788 , 0.982 , 1.027 ],\n",
       "        [2.38  , 3.06  , 1.592 , ..., 2.912 , 1.883 , 2.38  ]],\n",
       "\n",
       "       [[2.186 , 2.154 , 2.852 , ..., 1.352 , 2.39  , 2.186 ],\n",
       "        [1.614 , 1.237 , 2.164 , ..., 1.704 , 1.6875, 1.614 ],\n",
       "        [1.155 , 1.105 , 1.876 , ..., 1.146 , 1.268 , 1.155 ],\n",
       "        ...,\n",
       "        [0.8843, 1.111 , 1.189 , ..., 0.828 , 1.04  , 0.8843],\n",
       "        [1.027 , 1.338 , 1.24  , ..., 0.9575, 0.9126, 1.027 ],\n",
       "        [2.38  , 2.266 , 2.674 , ..., 2.11  , 1.711 , 2.38  ]]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get activations\n",
    "shape = (len(sequences), model._options[\"cnn_units\"], len(sequences[0]) - model._options[\"kernel_size\"] + 1)\n",
    "activations = __get_activations(model, data_loader, torch.zeros(shape, dtype=torch.float16))\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d2810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7588,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the indices of well predicted sequences\n",
    "if input_data == \"binary\":\n",
    "    indices = np.where((labels == 1.) & (outputs >= .5))[0]\n",
    "else:\n",
    "    labels_ixs = np.argsort(-labels.flatten())[:int(max(labels.shape) * .1)]\n",
    "    outputs_ixs = np.argsort(-outputs.flatten())[:int(max(outputs.shape) * .1)]\n",
    "    indices = np.intersect1d(labels_ixs, outputs_ixs)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4124f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del labels\n",
    "del outputs\n",
    "del data_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9610ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter, get the activation thresholds (i.e. ≥50%)\n",
    "act_thresholds = 0.5 * np.amax(activations[indices, :, :], axis=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16785ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_filter_sites(indices, record_ids, sequences, activations,\n",
    "                       threshold, kernel_size=19):\n",
    "    \"\"\"\n",
    "    For each filter and for each sequence, get sites reaching at least\n",
    "    ½ of the maximum activation value for that filter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    sites = []\n",
    "\n",
    "    # For each sequence...\n",
    "    for i in indices:\n",
    "\n",
    "        # Get start positions of sequence sites activating this filter\n",
    "        starts = np.where(activations[i, :] > threshold)\n",
    "\n",
    "        # For each start...\n",
    "        for j in starts[0]:\n",
    "\n",
    "            # Get site\n",
    "            seq = Seq(sequences[i][j:j+kernel_size])\n",
    "            seq_id = \"%s_%s_from=%s_to=%s\" % (record_ids[i][0],\n",
    "                                              record_ids[i][1],\n",
    "                                              j, j+kernel_size)\n",
    "            sites.append(SeqRecord(seq, id=seq_id, name=\"\",\n",
    "                                   description=\"\"))\n",
    "\n",
    "    return(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae102e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 33554.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each filter...\n",
    "for i in tqdm(range(len(act_thresholds)), total=len(act_thresholds)):\n",
    "\n",
    "    sites_file = os.path.join(output_dir, \"sites\", f\"filter{i}.fa\")\n",
    "    if not os.path.exists(sites_file):\n",
    "\n",
    "        # Get sites\n",
    "        sites = __get_filter_sites(indices, record_ids, sequences,\n",
    "                                   activations[:, i, :], act_thresholds[i],\n",
    "                                   model._options[\"kernel_size\"])\n",
    "\n",
    "        # Save sites\n",
    "        with open(sites_file, \"w\") as handle:\n",
    "            SeqIO.write(sites, handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b92884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_motif_from_sites(sites_file):\n",
    "    \"\"\"\n",
    "    From https://github.com/biopython/biopython/blob/master/Bio/motifs/__init__.py\n",
    "    Read the motif from JASPAR .sites file.\n",
    "    \"\"\"\n",
    "    alphabet = \"ACGTN\"\n",
    "    instances = []\n",
    "    pfm = {}\n",
    "\n",
    "    with open(sites_file) as handle:\n",
    "        for line in handle:\n",
    "            if not line.startswith(\">\"):\n",
    "                break\n",
    "            # line contains the header \">....\"\n",
    "            # now read the actual sequence\n",
    "            line = next(handle)\n",
    "            instance = \"\"\n",
    "            for c in line.strip().upper():\n",
    "                if c == c.upper():\n",
    "                    instance += c\n",
    "            instance = Seq(instance)\n",
    "            instances.append(instance)\n",
    "\n",
    "    instances = motifs.Instances(instances, alphabet)\n",
    "    motif = motifs.Motif(alphabet=alphabet, instances=instances)\n",
    "\n",
    "    for nt in alphabet[:-1]:\n",
    "        pfm.setdefault(nt, motif.counts[nt])\n",
    "\n",
    "    return(motifs.Motif(counts=pfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0297c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 3538.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF name\tZBED2.FL@hilly-bronze-frise\n",
      "Matrix ID\tfilter0\n",
      "Matrix:\n",
      "        0      1      2      3      4      5      6      7      8      9     10     11     12     13     14     15     16     17     18\n",
      "A:   5.00  26.00   8.00  19.00  11.00   7.00  21.00   0.00   0.00  19.00   6.00  14.00   2.00   2.00  13.00  20.00   1.00   7.00   1.00\n",
      "C:   0.00   1.00  18.00   3.00   7.00  14.00   6.00   1.00   0.00   7.00  20.00   1.00   1.00  13.00  13.00   4.00  16.00   1.00  21.00\n",
      "G:  13.00   0.00   0.00   0.00   9.00   0.00   0.00  10.00  15.00   0.00   1.00   0.00   8.00  12.00   0.00   3.00   9.00  13.00   1.00\n",
      "T:   9.00   0.00   1.00   5.00   0.00   6.00   0.00  16.00  12.00   1.00   0.00  12.00  16.00   0.00   1.00   0.00   1.00   6.00   4.00\n",
      "\n",
      "\n",
      "\n",
      "['_Motif__mask', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_background', '_pseudocounts', 'acc', 'alphabet', 'anticonsensus', 'background', 'base_id', 'collection', 'comment', 'consensus', 'counts', 'data_type', 'degenerate_consensus', 'format', 'instances', 'length', 'mask', 'matrix_id', 'medline', 'name', 'pazar_id', 'pseudocounts', 'pssm', 'pwm', 'reverse_complement', 'species', 'tax_group', 'tf_class', 'tf_family', 'version', 'weblogo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "profiles = []\n",
    "\n",
    "# For each filter...\n",
    "for i in tqdm(range(len(act_thresholds)), total=len(act_thresholds)):\n",
    "\n",
    "    motif_file = os.path.join(output_dir, \"motifs\", f\"filter{i}.jaspar\")\n",
    "    if not os.path.exists(motif_file):\n",
    "\n",
    "        # Get motif\n",
    "        sites_file = os.path.join(output_dir, \"sites\", f\"filter{i}.fa\")\n",
    "        motif = __get_motif_from_sites(sites_file)\n",
    "        motif.matrix_id = f\"filter{i}\"\n",
    "        motif.name = tf_name\n",
    "\n",
    "        # Save motif\n",
    "        with open(motif_file, \"w\") as handle:\n",
    "            handle.write(format(motif, \"jaspar\"))\n",
    "\n",
    "    profiles.append(motifs.read(open(motif_file), \"jaspar\"))\n",
    "\n",
    "print(profiles[0])\n",
    "print(dir(profiles[0]))\n",
    "\n",
    "meme_file = os.path.join(output_dir, \"motifs\", \"filters.meme\")\n",
    "if not os.path.exists(meme_file):\n",
    "\n",
    "    # Reformat motif\n",
    "    reformat_motifs(profiles, \"meme\", meme_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7208912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 11970.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each filter...\n",
    "for i in tqdm(range(len(act_thresholds)), total=len(act_thresholds)):\n",
    "\n",
    "    logo_file = os.path.join(output_dir, \"logos\", f\"filter{i}.png\")\n",
    "    if not os.path.exists(logo_file):\n",
    "\n",
    "        # Save logo\n",
    "        motif_file = os.path.join(output_dir, \"motifs\", f\"filter{i}.jaspar\")\n",
    "        fig = get_figure(motif_file)\n",
    "        fig.savefig(logo_file, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d49eb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27797282],\n",
       "       [ 0.57059216],\n",
       "       [ 0.45991048],\n",
       "       [-0.3499135 ],\n",
       "       [ 0.45256475],\n",
       "       [-0.56063855],\n",
       "       [-0.28398216],\n",
       "       [ 0.6471378 ],\n",
       "       [ 0.49125868],\n",
       "       [ 0.4584166 ],\n",
       "       [-0.45299268],\n",
       "       [-0.40856177],\n",
       "       [-0.5375612 ],\n",
       "       [ 0.66666996],\n",
       "       [ 0.42663684],\n",
       "       [-0.36597157]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get weights\n",
    "weights = model.final.weight.detach().cpu().numpy()\n",
    "weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71faf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "weights_file = os.path.join(output_dir, \"filter-weights.tsv\")\n",
    "if not os.path.exists(weights_file):\n",
    "    with open(weights_file, \"w\") as handle:\n",
    "        for i, weight in enumerate(weights.T):\n",
    "            s = \"\\t\".join(map(str, weight))\n",
    "            handle.write(f\"filter{i}\\t{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f25bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
