{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cde3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import click\n",
    "from click_option_group import optgroup\n",
    "import gc\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "bar_format = \"{percentage:3.0f}%|{bar:20}{r_bar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41502412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import CAM\n",
    "from jaspar import get_figure, reformat_motifs\n",
    "from sequence import one_hot_encode, rc_one_hot_encoding, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a52766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9254cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_file = \"../results/SMS.published/CAM/CTCF.NA@snappy-grey-markhor/best_model.pth.tar\"\n",
    "#training_file = \"../results/SMS.published/FASTA/Train/CTCF.NA@snappy-grey-markhor.fa.gz\"\n",
    "#output_dir = \"../results/SMS.published/CAM/CTCF.NA@snappy-grey-markhor/\"\n",
    "#tf_name = \"SOX2.NA\"\n",
    "#model_file = \"../results/Human-Mouse-Project/CAM/best_model.pth.tar\"\n",
    "#training_file = \"../results/Human-Mouse-Project/FASTA/train.fa.gz\"\n",
    "#output_dir = \"../results/Human-Mouse-Project/CAM/\"\n",
    "#tf_name = \"human-mouse\"\n",
    "model_file = \"../results/Human-Mouse-Project/CAM/best_model.pth.tar\"\n",
    "training_file = \"../results/Human-Mouse-Project/FASTA/train.fa.gz\"\n",
    "output_dir = \"../results/Human-Mouse-Project/CAM/\"\n",
    "tf_name = \"human-mouse\"\n",
    "batch_size = 2**6\n",
    "debugging = False\n",
    "threads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eba866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dirs\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for subdir in [\"sites\", \"motifs\", \"logos\"]:\n",
    "    if not os.path.isdir(os.path.join(output_dir, subdir)):\n",
    "        os.makedirs(os.path.join(output_dir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f23bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAM(\n",
       "  (linears): Sequential(\n",
       "    (0): Conv1d(512, 128, kernel_size=(19,), stride=(1,), padding=(19,), groups=128)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ExpAct()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): UnSqueeze()\n",
       "    (6): Conv1d(4864, 12800, kernel_size=(1,), stride=(1,), groups=128)\n",
       "    (7): BatchNorm1d(12800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.3, inplace=False)\n",
       "    (10): Conv1d(12800, 128, kernel_size=(1,), stride=(1,), groups=128)\n",
       "    (11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (final): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "selene_dict = torch.load(model_file)\n",
    "model = CAM(\n",
    "    selene_dict[\"options\"][\"cnn_units\"],\n",
    "    selene_dict[\"options\"][\"kernel_size\"],\n",
    "    selene_dict[\"options\"][\"sequence_length\"],\n",
    "    selene_dict[\"options\"][\"n_features\"],\n",
    "    selene_dict[\"options\"][\"clamp_weights\"],\n",
    "    selene_dict[\"options\"][\"no_padding\"],\n",
    "    selene_dict[\"options\"][\"weights_file\"],\n",
    ")\n",
    "model.load_state_dict(selene_dict[\"state_dict\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13dfb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "if selene_dict[\"options\"][\"no_padding\"]:\n",
    "    padding = 0\n",
    "else:\n",
    "    padding = selene_dict[\"options\"][\"kernel_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe340ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Xs_ys_record_ids_sequences(fasta_file, debugging=False, reverse_complement=False):\n",
    "\n",
    "    # Initialize\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    record_ids = []\n",
    "    sequences = []\n",
    "\n",
    "    # Xs / ys\n",
    "    handle = __get_handle(fasta_file)\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        _, y_list = record.description.split()\n",
    "        Xs.append(one_hot_encode(str(record.seq).upper()))\n",
    "        ys.append([float(y) for y in y_list.split(\";\")])\n",
    "        record_ids.append((record.id, \"+\"))\n",
    "        sequences.append(str(record.seq))\n",
    "\n",
    "    # Reverse complement\n",
    "    if reverse_complement:\n",
    "        n = len(Xs)\n",
    "        for i in range(n):\n",
    "            Xs.append(rc_one_hot_encoding(Xs[i]))\n",
    "            ys.append(ys[i])\n",
    "            record_ids.append((record_ids[i][0], \"-\"))\n",
    "            sequences.append(rc(sequences[i]))\n",
    "\n",
    "    # Return 1,000 sequences\n",
    "    if debugging:\n",
    "        return(np.array(Xs)[:10000], np.array(ys)[:10000], \n",
    "               np.array(record_ids)[:10000])\n",
    "\n",
    "    return(np.array(Xs), np.array(ys), np.array(record_ids), sequences)\n",
    "\n",
    "def _get_data_loader(Xs_train, ys_train, batch_size=2**6, threads=1):\n",
    "\n",
    "    # TensorDatasets\n",
    "    train_set = TensorDataset(torch.Tensor(Xs_train), torch.Tensor(ys_train))\n",
    "\n",
    "    # DataLoaders\n",
    "    kwargs = dict(batch_size=batch_size, num_workers=threads)\n",
    "    train_loader = DataLoader(train_set, **kwargs)\n",
    "\n",
    "    return(train_loader)\n",
    "\n",
    "def __get_handle(file_name):\n",
    "    if file_name.endswith(\"gz\"):\n",
    "        handle = gzip.open(file_name, \"rt\")\n",
    "    else:\n",
    "        handle = open(file_name, \"rt\")\n",
    "    return(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4df12ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNNNNNNNNNNNNNNNNNNaacctttgtgtctagctcagggattgtaaatacaccaatcggcactctgtctctagctcaaggtttgtaaacacaccaatcaacaccctgtgtctagctcagggtttgtgaatgcaccaatccacactctgtatctagctactctggtggggacttggagaaccttttgtgtggacactctgtatctagctaatctggtggcctagtggagaacctttgtgtgtagctcagggattgtaaacgcaccaatNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNAGGCCTCGCCACTTGAGAGTGAAAGGCATTGTTCATTCCCCAATGACAGCATGGCTCTTAAGCAAGAGAGGAAGCAAAGGAAGTTGTCCCTCAGAACAGTGCTCCCTCCAAGGGCACAGGAGGAAGTGCTCTCCTCCGCAAGTGGATTTCCTGTCAGGCCAGACAGTCTTCTGCGGTGCTCACAACCCAGCTCTGCAGCTGTTTTTGCAGAGGTCCAACTGCACGTCGTCACGAGTTCAGCTAATCCAACNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNCCAGCCTTCTAGTGTGCCCCTGCCCAACGGGAGGGAGGAGGGAGCGGGGAGCCCCGGCGAGGGAGGAGAGGGCGGGCCCTGAGAGGAGTTTGAAAAGAGGAAGGAAGTGGGGCCCTGCGGCGCCCAGCCACCCCCTGACGGCTTCCCCACGGGAGGACGCGAGGCCCCGGCCCAGCCATGGCCCCCTGGCGCAAAGCTGACAAGGAGCGGCACGGCGTGGGTAGGTGCGGGCCCCAGGGCGCGGCAGGGANNNNNNNNNNNNNNNNNNN',\n",
       "       ...,\n",
       "       'NNNNNNNNNNNNNNNNNNNttgggcctgggggggcagggaggctttgtggagagagagattcaacctgagatctgcaggacaggggagggacagatgCATGACTCAGAGTGGGCGGGGGACTGCAACATCATCTGTGCTTGAGGTTTCCCTGATCGCAGTCCAGTTCCTCTTAGTGAAATACTTACACATTGGGGAAATTCATGAGGGGCAAGGGCCCTGGTGCTGCCAGAGAGAAGGGAAGGGTAGGAAGCAATGGGTACACGGTGTGNNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNTGAGTTCTAGCTGGAGATGTGTACAAAAGGTGCGCAGCAGGGTCTTCCTCAGTGGCTGTTGAAGAGGCTGAAGGCAAAGAAGCCTTTTGATGCCAACAAACTGTATTGCAGTGAAATGCAGGCCATATTGCTCCAGGACAATGATGAAAACAGGAAATTGCTTGGGGAGCTGGATAGAATTGATGCACTTCTTCACAGTTATCTGTGTTTAAAAGACACAATCCCAGCACAGCAAAGGAGCAGGAGATGANNNNNNNNNNNNNNNNNNN',\n",
       "       'NNNNNNNNNNNNNNNNNNNTAACGAAAGGCTCTACTTCACTTAGTAACTTCCATTTTTAGAGCAGGAAGCAATTTGTTCAGATTCTGCTTGTGCTAGAGAAGGCAAGTTTCCTTCCAGGGTGGTGGAAAGATGCAGGAAGGGGAGTAACCATGGCAACCTGCCCAGCTATGTGGACCAAGATAGTATTGGGGCCCGTGTCCTGGCCTAGTCACTGCTTAGTCAGGGTGGTCCCTCCCTTTCCCACTTCCTTGGCTAGAATGCTGACTTCNNNNNNNNNNNNNNNNNNN'],\n",
       "      dtype='<U288')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Xs/ys/record ids\n",
    "Xs, ys, record_ids, sequences = _get_Xs_ys_record_ids_sequences(training_file, debugging, True)\n",
    "\n",
    "# Get DataLoader\n",
    "data_loader = _get_data_loader(list(Xs), list(ys), batch_size, threads)\n",
    "\n",
    "# Input data\n",
    "if np.unique(ys[:, 0]).size == 2:\n",
    "    input_data = \"binary\"\n",
    "else:\n",
    "    input_data = \"linear\"\n",
    "\n",
    "# Fix sequences\n",
    "for i in range(len(sequences)):\n",
    "    sequences[i] = \"N\" * padding + sequences[i] + \"N\" * padding\n",
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16930941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del Xs\n",
    "del ys\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15222d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3983/3983 [01:06<00:00, 60.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "# Get sequences, outputs, and labels\n",
    "with torch.no_grad():\n",
    "    for x, label in tqdm(data_loader, total=len(data_loader)):\n",
    "\n",
    "        # Get outputs\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        if input_data == \"binary\":\n",
    "            out = torch.sigmoid(out)\n",
    "        outputs.extend(out.detach().cpu().numpy())\n",
    "\n",
    "        # Get labels\n",
    "        labels.extend(label.numpy())\n",
    "\n",
    "# To NumPy\n",
    "outputs = np.array(outputs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d2c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_activations(model, data_loader, activations):\n",
    "\n",
    "    # Counter\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(data_loader, total=len(data_loader)):\n",
    "            x = x.to(device)\n",
    "            x = x.repeat(1, model._options[\"cnn_units\"], 1)\n",
    "            activations[idx:idx+x.shape[0], :, :] = model.linears[:3](x).cpu()\n",
    "            idx += x.shape[0]           \n",
    "\n",
    "    return(activations.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0511c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3983/3983 [01:18<00:00, 51.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.248 , 1.353 , 1.317 , ..., 1.286 , 1.004 , 1.248 ],\n",
       "        [0.852 , 1.071 , 0.885 , ..., 0.9917, 0.8813, 0.852 ],\n",
       "        [0.845 , 0.6577, 0.525 , ..., 0.961 , 0.793 , 0.845 ],\n",
       "        ...,\n",
       "        [1.152 , 1.29  , 1.147 , ..., 1.395 , 1.965 , 1.152 ],\n",
       "        [1.784 , 1.342 , 1.215 , ..., 1.8545, 1.94  , 1.784 ],\n",
       "        [1.417 , 1.762 , 1.496 , ..., 1.212 , 1.22  , 1.417 ]],\n",
       "\n",
       "       [[1.248 , 1.353 , 1.305 , ..., 1.54  , 1.26  , 1.248 ],\n",
       "        [0.852 , 1.071 , 0.7363, ..., 1.088 , 0.9316, 0.852 ],\n",
       "        [0.845 , 0.6577, 1.015 , ..., 0.983 , 0.99  , 0.845 ],\n",
       "        ...,\n",
       "        [1.152 , 1.29  , 0.938 , ..., 0.777 , 0.7075, 1.152 ],\n",
       "        [1.784 , 1.342 , 2.064 , ..., 2.129 , 1.847 , 1.784 ],\n",
       "        [1.417 , 1.762 , 1.113 , ..., 1.295 , 1.826 , 1.417 ]],\n",
       "\n",
       "       [[1.248 , 1.136 , 1.033 , ..., 1.48  , 1.435 , 1.248 ],\n",
       "        [0.852 , 0.841 , 0.9263, ..., 0.8745, 0.9097, 0.852 ],\n",
       "        [0.845 , 0.731 , 1.156 , ..., 0.956 , 0.9917, 0.845 ],\n",
       "        ...,\n",
       "        [1.152 , 1.213 , 0.9434, ..., 1.969 , 1.263 , 1.152 ],\n",
       "        [1.784 , 1.733 , 2.074 , ..., 1.832 , 1.853 , 1.784 ],\n",
       "        [1.417 , 1.234 , 1.49  , ..., 1.375 , 1.543 , 1.417 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.266 , 1.11  , 1.148 , ..., 1.11  , 1.321 , 1.266 ],\n",
       "        [0.877 , 0.957 , 1.107 , ..., 0.641 , 0.8306, 0.877 ],\n",
       "        [0.8584, 0.836 , 0.7124, ..., 0.725 , 0.803 , 0.8584],\n",
       "        ...,\n",
       "        [1.09  , 0.9766, 0.986 , ..., 1.696 , 1.125 , 1.09  ],\n",
       "        [1.945 , 1.212 , 1.689 , ..., 2.145 , 1.834 , 1.945 ],\n",
       "        [1.436 , 1.638 , 1.418 , ..., 1.278 , 1.213 , 1.436 ]],\n",
       "\n",
       "       [[1.266 , 1.11  , 1.403 , ..., 1.498 , 1.453 , 1.266 ],\n",
       "        [0.877 , 0.957 , 1.0625, ..., 0.9   , 0.937 , 0.877 ],\n",
       "        [0.8584, 0.836 , 1.099 , ..., 0.97  , 1.007 , 0.8584],\n",
       "        ...,\n",
       "        [1.09  , 0.9766, 1.005 , ..., 1.875 , 1.195 , 1.09  ],\n",
       "        [1.945 , 1.212 , 3.469 , ..., 1.998 , 2.021 , 1.945 ],\n",
       "        [1.436 , 1.638 , 1.15  , ..., 1.393 , 1.563 , 1.436 ]],\n",
       "\n",
       "       [[1.266 , 1.11  , 1.417 , ..., 1.095 , 1.277 , 1.266 ],\n",
       "        [0.877 , 0.957 , 1.278 , ..., 1.087 , 0.96  , 0.877 ],\n",
       "        [0.8584, 0.836 , 0.571 , ..., 0.799 , 1.005 , 0.8584],\n",
       "        ...,\n",
       "        [1.09  , 0.9766, 1.232 , ..., 1.144 , 0.6646, 1.09  ],\n",
       "        [1.945 , 1.212 , 2.04  , ..., 2.432 , 2.014 , 1.945 ],\n",
       "        [1.436 , 1.638 , 1.548 , ..., 1.034 , 1.853 , 1.436 ]]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get activations\n",
    "shape = (len(sequences), model._options[\"cnn_units\"], len(sequences[0]) - model._options[\"kernel_size\"] + 1)\n",
    "activations = __get_activations(model, data_loader, torch.zeros(shape, dtype=torch.float16))\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d2810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202933,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the indices of well predicted sequences\n",
    "if input_data == \"binary\":\n",
    "    indices = np.where((labels == 1.) & (outputs >= .5))[0]\n",
    "else:\n",
    "    labels_ixs = np.argsort(-labels.flatten())[:int(max(labels.shape) * .1)]\n",
    "    outputs_ixs = np.argsort(-outputs.flatten())[:int(max(outputs.shape) * .1)]\n",
    "    indices = np.intersect1d(labels_ixs, outputs_ixs)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4124f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del labels\n",
    "del outputs\n",
    "del data_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter, get the activation thresholds (i.e. ≥50%)\n",
    "act_thresholds = 0.5 * np.amax(activations[indices, :, :], axis=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16785ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_filter_sites(indices, record_ids, sequences, activations,\n",
    "                       threshold, kernel_size=19):\n",
    "    \"\"\"\n",
    "    For each filter and for each sequence, get sites reaching at least\n",
    "    ½ of the maximum activation value for that filter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    sites = []\n",
    "\n",
    "    # For each sequence...\n",
    "    for i in indices:\n",
    "\n",
    "        # Get start positions of sequence sites activating this filter\n",
    "        starts = np.where(activations[i, :] > threshold)\n",
    "\n",
    "        # For each start...\n",
    "        for j in starts[0]:\n",
    "\n",
    "            # Get site\n",
    "            seq = Seq(sequences[i][j:j+kernel_size])\n",
    "            seq_id = \"%s_%s_from=%s_to=%s\" % (record_ids[i][0],\n",
    "                                              record_ids[i][1],\n",
    "                                              j, j+kernel_size)\n",
    "            sites.append(SeqRecord(seq, id=seq_id, name=\"\",\n",
    "                                   description=\"\"))\n",
    "\n",
    "    return(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae102e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter...\n",
    "for i in tqdm(range(len(act_thresholds)), total=len(act_thresholds)):\n",
    "\n",
    "    sites_file = os.path.join(output_dir, \"sites\", f\"filter{i}.fa\")\n",
    "    if not os.path.exists(sites_file):\n",
    "\n",
    "        # Get sites\n",
    "        sites = __get_filter_sites(indices, record_ids, sequences,\n",
    "                                   activations[:, i, :], act_thresholds[i],\n",
    "                                   model._options[\"kernel_size\"])\n",
    "\n",
    "        # Save sites\n",
    "        with open(sites_file, \"w\") as handle:\n",
    "            SeqIO.write(sites, handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b92884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_motif_from_sites(sites_file):\n",
    "    \"\"\"\n",
    "    From https://github.com/biopython/biopython/blob/master/Bio/motifs/__init__.py\n",
    "    Read the motif from JASPAR .sites file.\n",
    "    \"\"\"\n",
    "    alphabet = \"ACGTN\"\n",
    "    instances = []\n",
    "    pfm = {}\n",
    "\n",
    "    with open(sites_file) as handle:\n",
    "        for line in handle:\n",
    "            if not line.startswith(\">\"):\n",
    "                break\n",
    "            # line contains the header \">....\"\n",
    "            # now read the actual sequence\n",
    "            line = next(handle)\n",
    "            instance = \"\"\n",
    "            for c in line.strip().upper():\n",
    "                if c == c.upper():\n",
    "                    instance += c\n",
    "            instance = Seq(instance)\n",
    "            instances.append(instance)\n",
    "\n",
    "    instances = motifs.Instances(instances, alphabet)\n",
    "    motif = motifs.Motif(alphabet=alphabet, instances=instances)\n",
    "\n",
    "    for nt in alphabet[:-1]:\n",
    "        pfm.setdefault(nt, motif.counts[nt])\n",
    "\n",
    "    return(motifs.Motif(counts=pfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0297c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "profiles = []\n",
    "\n",
    "# For each filter...\n",
    "for i in tqdm(range(len(act_thresholds)), total=len(act_thresholds)):\n",
    "\n",
    "    motif_file = os.path.join(output_dir, \"motifs\", f\"filter{i}.jaspar\")\n",
    "    if not os.path.exists(motif_file):\n",
    "\n",
    "        # Get motif\n",
    "        sites_file = os.path.join(output_dir, \"sites\", f\"filter{i}.fa\")\n",
    "        motif = __get_motif_from_sites(sites_file)\n",
    "        motif.matrix_id = f\"filter{i}\"\n",
    "        motif.name = tf_name\n",
    "\n",
    "        # Save motif\n",
    "        with open(motif_file, \"w\") as handle:\n",
    "            handle.write(format(motif, \"jaspar\"))\n",
    "\n",
    "    profiles.append(motifs.read(open(motif_file), \"jaspar\"))\n",
    "\n",
    "meme_file = os.path.join(output_dir, \"motifs\", \"filters.meme\")\n",
    "if not os.path.exists(meme_file):\n",
    "\n",
    "    # Reformat motif\n",
    "    reformat_motifs(profiles, \"meme\", meme_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7208912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter...\n",
    "for i in tqdm(range(len(act_thresholds)), total=len(act_thresholds)):\n",
    "\n",
    "    logo_file = os.path.join(output_dir, \"logos\", f\"filter{i}.png\")\n",
    "    if not os.path.exists(logo_file):\n",
    "\n",
    "        # Save logo\n",
    "        motif_file = os.path.join(output_dir, \"motifs\", f\"filter{i}.jaspar\")\n",
    "        fig = get_figure(motif_file)\n",
    "        fig.savefig(logo_file, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49eb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights\n",
    "weights = model.final.weight.detach().cpu().numpy()\n",
    "weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71faf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "weights_file = os.path.join(output_dir, \"filter-weights.tsv\")\n",
    "if not os.path.exists(weights_file):\n",
    "    with open(weights_file, \"w\") as handle:\n",
    "        for i, weight in enumerate(weights.T):\n",
    "            s = \"\\t\".join(map(str, weight))\n",
    "            handle.write(f\"filter{i}\\t{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f25bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-choice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
