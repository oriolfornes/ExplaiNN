{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cde3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import click\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "bar_format = \"{percentage:3.0f}%|{bar:20}{r_bar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41502412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import CAM, get_metrics\n",
    "from jaspar import get_figure, reformat_motif\n",
    "from sequence import one_hot_encode, rc_one_hot_encoding, rc\n",
    "from train import _get_data_loaders, __get_handle\n",
    "from predict import _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a52766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9254cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/md1/home/oriol/CAM/results/IRF4\"\n",
    "ASSAY = \"Affi-seq\"\n",
    "LABEL = \"WT\"\n",
    "model_file = f\"{BASE_DIR}/CAM/{ASSAY}/{LABEL}/best_model.pth.tar\"\n",
    "training_file = f\"{BASE_DIR}/FASTA/{ASSAY}/{LABEL}.train.fa.gz\"\n",
    "validation_file = f\"{BASE_DIR}/FASTA/{ASSAY}/{LABEL}.validation.fa.gz\"\n",
    "batch_size = 2**6\n",
    "debugging = False\n",
    "name = f\"{ASSAY}.{LABEL}\"\n",
    "output_dir = f\"{BASE_DIR}/CAM/{ASSAY}/{LABEL}\"\n",
    "rev_complement = True\n",
    "threads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a4949a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "torch.set_num_threads(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eba866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dirs\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for subdir in [\"sites\", \"motifs\", \"logos\"]:\n",
    "    if not os.path.isdir(os.path.join(output_dir, subdir)):\n",
    "        os.makedirs(os.path.join(output_dir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f23bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAM(\n",
       "  (linears): Sequential(\n",
       "    (0): Conv1d(64, 16, kernel_size=(19,), stride=(1,), padding=(19,), groups=16)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ExpAct()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): UnSqueeze()\n",
       "    (6): Conv1d(176, 1600, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (7): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.3, inplace=False)\n",
       "    (10): Conv1d(1600, 16, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (11): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (final): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model\n",
    "selene_dict = torch.load(model_file)\n",
    "model = CAM(\n",
    "    selene_dict[\"options\"][\"cnn_units\"],\n",
    "    selene_dict[\"options\"][\"kernel_size\"],\n",
    "    selene_dict[\"options\"][\"sequence_length\"],\n",
    "    selene_dict[\"options\"][\"n_features\"],\n",
    "    selene_dict[\"options\"][\"clamp_weights\"],\n",
    "    selene_dict[\"options\"][\"no_padding\"],\n",
    "    selene_dict[\"options\"][\"weights_file\"],\n",
    ")\n",
    "model.load_state_dict(selene_dict[\"state_dict\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62dae43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Xs_ys_seq_ids_seqs(fasta_file, debugging=False, reverse_complement=False):\n",
    "\n",
    "    # Initialize\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    seq_ids = []\n",
    "    seqs = []\n",
    "\n",
    "    # Xs / ys\n",
    "    handle = __get_handle(fasta_file)\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        _, y_list = record.description.split()\n",
    "        Xs.append(one_hot_encode(str(record.seq).upper()))\n",
    "        ys.append([float(y) for y in y_list.split(\";\")])\n",
    "        seq_ids.append((record.id, \"+\"))\n",
    "        seqs.append(str(record.seq))\n",
    "    handle.close()\n",
    "\n",
    "    # Reverse complement\n",
    "    if reverse_complement:\n",
    "        n = len(Xs)\n",
    "        for i in range(n):\n",
    "            Xs.append(rc_one_hot_encoding(Xs[i]))\n",
    "            ys.append(ys[i])\n",
    "            seq_ids.append((seq_ids[i][0], \"-\"))\n",
    "            seqs.append(rc(seqs[i]))\n",
    "\n",
    "    # Return 1,000 sequences\n",
    "    if debugging:\n",
    "        return(np.array(Xs)[:10000], np.array(ys)[:10000], \n",
    "               np.array(seq_ids)[:10000])\n",
    "\n",
    "    return(np.array(Xs), np.array(ys), np.array(seq_ids), seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13dfb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Load Data  #\n",
    "##############\n",
    "\n",
    "# Initialize\n",
    "Xs = {}\n",
    "ys = {}\n",
    "seq_ids = {}\n",
    "seqs = {}\n",
    "data_loaders = {}\n",
    "\n",
    "# Get data\n",
    "for train_validation in [\"train\", \"validation\"]:\n",
    "    if train_validation == \"train\":\n",
    "        rev_complement_option = rev_complement\n",
    "        fasta_file = training_file\n",
    "    else:\n",
    "        rev_complement_option = True\n",
    "        fasta_file = validation_file\n",
    "    Xs_arr, ys_arr, seq_ids_arr, seqs_arr = _get_Xs_ys_seq_ids_seqs(fasta_file, debugging, rev_complement_option)\n",
    "    Xs.setdefault(train_validation, Xs_arr)\n",
    "    ys.setdefault(train_validation, ys_arr)\n",
    "    seq_ids.setdefault(train_validation, seq_ids_arr)\n",
    "    seqs.setdefault(train_validation, seqs_arr)\n",
    "\n",
    "# Get DataLoaders\n",
    "for train_validation in [\"train\", \"validation\"]:\n",
    "    data_loader = _get_data_loaders(list(Xs[train_validation]), list(ys[train_validation]), batch_size=batch_size)\n",
    "    data_loaders.setdefault(train_validation, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28203600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array(['NNNNNNNNNNNNNNNNNNNAAAAAGAGTGTTCCAAAACTGCTCAATCATGAAATAGGATCAACCCTGGGAGATGAATGTANNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNATTCATGGATTGGAAGAATCAGTATTGTTAAGATATTAAGACTAACCAAAGCAATCTGCAGNNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNCATTTTCACTTCCAAAGGTAGATTGTGAAACCGTGGAAGCATGATTAAATTAGATCGGAAANNNNNNNNNNNNNNNNNNN',\n",
       "        ...,\n",
       "        'NNNNNNNNNNNNNNNNNNNGATCTCTCATTCTCTATTTAGAAACCAGCATGTCAGGATCCAAGCAGAAAAATCAGTAAAANNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNTCACTCATCAGAAAACCCAAGACCTAAAAAGCTCTGAAACTGCGTGCACGCTGCCAAAACCNNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNCCTGAGAGGAAAGATGGCCACTGAGATGGGCGGGGGACGCACATGCCCGCTGGCTGAACAGNNNNNNNNNNNNNNNNNNN'],\n",
       "       dtype='<U99'),\n",
       " 'validation': array(['NNNNNNNNNNNNNNNNNNNACCAAGAACCGGCGGCACCGAGAACCGGCGGCACCGAGAATCGGCAGCACCGAGAACCGGCNNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNGTTTCGGTGTTTCAGTGTTTCGGTGTTTCTCTGTTCAGTGTTTTGGTGTTTCAGTGCTTCANNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNCGGCGGAGCTCTCGGGTCGCTAGCAACATTAAGGTTTCGCTTTCAGATCGGAAGAGCACACNNNNNNNNNNNNNNNNNNN',\n",
       "        ...,\n",
       "        'NNNNNNNNNNNNNNNNNNNGATCTCTAGGATTCAGACCCGAAACCAAGGAATCAGACCTGAAACCAGGCCTGGGCCTGCCNNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNAGTAAGTTTAAATCCCCAGAGACACTGTGTTCATGCTTTAGTAGACATCAGATACCAAAACNNNNNNNNNNNNNNNNNNN',\n",
       "        'NNNNNNNNNNNNNNNNNNNGATGAGATAAAGCTTTTACAGAATTCCGTGATGTGATTGTGAATTGTCTTCTCCCTTTCACNNNNNNNNNNNNNNNNNNN'],\n",
       "       dtype='<U99')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "# Interpret  #\n",
    "############## \n",
    "\n",
    "# Initialize\n",
    "outputs = {}\n",
    "labels = {}\n",
    "activations = {}\n",
    "jaspar_motifs = []\n",
    "if np.unique(ys[\"train\"][:, 0]).size == 2:\n",
    "    input_data = \"binary\"\n",
    "else:\n",
    "    input_data = \"linear\"\n",
    "if selene_dict[\"options\"][\"no_padding\"]:\n",
    "    padding = 0\n",
    "else:\n",
    "    padding = selene_dict[\"options\"][\"kernel_size\"]\n",
    "\n",
    "# Fix sequences\n",
    "for train_validation in [\"train\", \"validation\"]:\n",
    "    for i in range(len(seqs[train_validation])):\n",
    "        seqs[train_validation][i] = \"N\" * padding + seqs[train_validation][i] + \"N\" * padding\n",
    "    seqs[train_validation] = np.array(seqs[train_validation])\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e750c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████| 58612/58612 [03:06<00:00, 314.00it/s]\n",
      "100%|████████████████████| 14653/14653 [00:48<00:00, 300.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': array([[0.88821423, 0.20360187, 0.02397364],\n",
       "        [0.8642258 , 0.2042416 , 0.01978515],\n",
       "        [0.11346776, 0.4690759 , 0.38081092],\n",
       "        ...,\n",
       "        [0.69508195, 0.18725295, 0.05029937],\n",
       "        [0.44129035, 0.2759167 , 0.16789351],\n",
       "        [0.7607313 , 0.10816242, 0.10274088]], dtype=float32),\n",
       " 'validation': array([[0.3250231 , 0.30424657, 0.28533012],\n",
       "        [0.06168558, 0.46682075, 0.56772155],\n",
       "        [0.04809458, 0.39926314, 0.67623323],\n",
       "        ...,\n",
       "        [0.00565218, 0.30247366, 0.91212475],\n",
       "        [0.82167125, 0.20787889, 0.03382861],\n",
       "        [0.8072828 , 0.23883036, 0.03381034]], dtype=float32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predict\n",
    "for train_validation in [\"train\", \"validation\"]:\n",
    "    outputs_arr, labels_arr = _predict(model, data_loaders[train_validation], input_data)\n",
    "    outputs.setdefault(train_validation, outputs_arr)\n",
    "    labels.setdefault(train_validation, labels_arr)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6473d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_activations(model, data_loader, x, y, z):\n",
    "\n",
    "    # Counter\n",
    "    idx = 0\n",
    "    activations = torch.zeros((x, y, z), dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(iter(data_loader), total=len(data_loader),\n",
    "                bar_format=bar_format):\n",
    "\n",
    "            # Get activations\n",
    "            x = x.to(device)\n",
    "            x = x.repeat(1, model._options[\"cnn_units\"], 1)\n",
    "            activations[idx:idx+x.shape[0], :, :] = model.linears[:3](x).cpu()\n",
    "            idx += x.shape[0]           \n",
    "\n",
    "    return(activations.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations\n",
    "for train_validation in [\"train\", \"validation\"]:\n",
    "    x = len(seqs[train_validation])\n",
    "    y = model._options[\"cnn_units\"]\n",
    "    z = len(seqs[train_validation][0]) - model._options[\"kernel_size\"] + 1\n",
    "    activations_arr = _get_activations(model, data_loaders[train_validation], x, y, z)\n",
    "    activations.setdefault(train_validation, activations_arr)\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f356147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of well predicted sequences\n",
    "if input_data == \"binary\":\n",
    "    idxs = np.where((labels[\"train\"] == 1.) & (outputs[\"train\"] >= .5))[0]\n",
    "else:\n",
    "    l_idxs = np.argsort(-labels[\"train\"].flatten())[:int(max(labels[\"train\"].shape) * .1)]\n",
    "    o_idxs = np.argsort(-outputs[\"train\"].flatten())[:int(max(outputs[\"train\"].shape) * .1)]\n",
    "    idxs = np.intersect1d(l_idxs, o_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_sites(handle, idxs, seq_ids, seqs, activations, threshold,\n",
    "               kernel_size=19):\n",
    "    \"\"\"\n",
    "    For each filter and each sequence, get sites reaching at least ½ of the\n",
    "    maximum activation value for that filter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    count = 0\n",
    "\n",
    "    # For each sequence...\n",
    "    for i in idxs:\n",
    "\n",
    "        # Get start positions of sequence sites activating this filter\n",
    "        starts = np.where(activations[i, :] > threshold)\n",
    "\n",
    "        # For each start...\n",
    "        for j in starts[0]:\n",
    "\n",
    "            # Get site\n",
    "            record_id = seq_ids[i][0]\n",
    "            strand = seq_ids[i][1]\n",
    "            start = j\n",
    "            end = j+kernel_size\n",
    "            seq = Seq(seqs[i][start:end])\n",
    "            seq_id = \"%s_%s_from=%s_to=%s\" % (record_id, strand, start, end)\n",
    "            record = SeqRecord(seq, id=seq_id, name=\"\", description=\"\")\n",
    "            handle.write(record.format(\"fasta\"))\n",
    "\n",
    "            # If count reaches 1M, this filter is way too ubiquitous!!!\n",
    "            count += 1\n",
    "            if count == 1e6:\n",
    "                return\n",
    "\n",
    "def _get_motif(handle):\n",
    "    \"\"\"\n",
    "    From https://github.com/biopython/biopython/blob/master/Bio/motifs/__init__.py\n",
    "    Read the motif from JASPAR .sites file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    alphabet = \"ACGTN\"\n",
    "    instances = []\n",
    "    pfm = {}\n",
    "\n",
    "    for line in handle:\n",
    "        if not line.startswith(\">\"):\n",
    "            break\n",
    "        # line contains the header \">....\"\n",
    "        # now read the actual sequence\n",
    "        line = next(handle)\n",
    "        instance = \"\"\n",
    "        for c in line.strip().upper():\n",
    "            if c == c.upper():\n",
    "                instance += c\n",
    "        instance = Seq(instance)\n",
    "        instances.append(instance)\n",
    "\n",
    "    instances = motifs.Instances(instances, alphabet)\n",
    "    motif = motifs.Motif(alphabet=alphabet, instances=instances)\n",
    "\n",
    "    for nt in alphabet[:-1]:\n",
    "        pfm.setdefault(nt, motif.counts[nt])\n",
    "\n",
    "    return(motifs.Motif(counts=pfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef28254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter, get the activation threshold (i.e. ≥50%)\n",
    "thresholds = 0.5 * np.amax(activations[\"train\"][idxs, :, :], axis=(0, 2))\n",
    "\n",
    "# For each filter...\n",
    "for i in tqdm(range(selene_dict[\"options\"][\"cnn_units\"]),\n",
    "              total=selene_dict[\"options\"][\"cnn_units\"],\n",
    "              bar_format=bar_format):\n",
    "\n",
    "    # Get sites\n",
    "    sites_file = os.path.join(output_dir, \"sites\",\n",
    "        f\"filter{i}.fa.gz\")\n",
    "    if not os.path.exists(sites_file):\n",
    "        handle = __get_handle(sites_file, \"wt\")\n",
    "        _get_sites(handle, idxs, seq_ids[\"train\"], seqs[\"train\"], activations[\"train\"][:, i, :],\n",
    "            thresholds[i], model._options[\"kernel_size\"])\n",
    "        handle.close()\n",
    "\n",
    "    # Get motif\n",
    "    motif_file = os.path.join(output_dir, \"motifs\",\n",
    "        f\"filter{i}.jaspar\")\n",
    "    if not os.path.exists(motif_file):\n",
    "        handle = __get_handle(sites_file)\n",
    "        motif = _get_motif(handle)\n",
    "        handle.close()\n",
    "        motif.matrix_id = f\"filter{i}\"\n",
    "        motif.name = name\n",
    "        handle = __get_handle(motif_file, \"wt\")\n",
    "        handle.write(format(motif, \"jaspar\"))\n",
    "        handle.close()\n",
    "        jaspar_motifs.append(motif)\n",
    "\n",
    "    # Get logos\n",
    "    for reverse_complement in [False, True]:\n",
    "        if reverse_complement:\n",
    "            logo_file = os.path.join(output_dir, \"logos\",\n",
    "                f\"filter{i}.rev.png\")\n",
    "        else:\n",
    "            logo_file = os.path.join(output_dir, \"logos\",\n",
    "                f\"filter{i}.fwd.png\")\n",
    "        if not os.path.exists(logo_file):\n",
    "            fig = get_figure(motif_file, reverse_complement)\n",
    "            fig.savefig(logo_file, bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "# Get motifs in MEME format\n",
    "meme_file = os.path.join(output_dir, \"motifs\", \"filters.meme\")\n",
    "if not os.path.exists(meme_file):\n",
    "    reformat_motif(jaspar_motifs, \"meme\", meme_file)\n",
    "\n",
    "# Get weights\n",
    "weights_file = os.path.join(output_dir, \"weights.tsv\")\n",
    "if not os.path.exists(weights_file):\n",
    "    weights = model.final.weight.detach().cpu().numpy()\n",
    "    handle = __get_handle(weights_file, \"wt\")\n",
    "    for i, weight in enumerate(weights.T):\n",
    "        s = \"\\t\".join(map(str, weight))\n",
    "        handle.write(f\"filter{i}\\t{s}\\n\")\n",
    "    handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_performances(handle, activations, ys, metric):\n",
    "   \n",
    "    # Initialize\n",
    "    scores = []\n",
    "    sum_activations = __split_arr_and_combine(activations, combine=True)\n",
    "    ys = __split_arr_and_combine(ys)\n",
    "\n",
    "    for y in ys.T:\n",
    "        scores.append(metric(y, sum_activations))\n",
    "\n",
    "    return(scores)\n",
    "\n",
    "def __split_arr_and_combine(arr, combine=False):\n",
    "\n",
    "    half_arr = arr[:len(arr)//2]\n",
    "    other_half_arr = arr[len(arr)//2:]\n",
    "\n",
    "    if combine:\n",
    "        return(np.sum(np.concatenate((half_arr, other_half_arr), axis=1), axis=1))\n",
    "    else:\n",
    "        return(half_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f25bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "metrics = get_metrics(input_data=input_data)\n",
    "\n",
    "# For each metric...\n",
    "for m in metrics:\n",
    "\n",
    "    # Get performances\n",
    "    performance_file = os.path.join(output_dir, f\"{m}.tsv\")\n",
    "    handle = __get_handle(performance_file, \"wt\")\n",
    "\n",
    "    # For each filter...\n",
    "    for i in tqdm(range(selene_dict[\"options\"][\"cnn_units\"]),\n",
    "                  total=selene_dict[\"options\"][\"cnn_units\"],\n",
    "                  bar_format=bar_format):\n",
    "\n",
    "        # Get performances\n",
    "        scores = _get_performances(handle, activations[\"validation\"][:, i, :], ys[\"validation\"],\n",
    "                                   metrics[m])\n",
    "        s = \"\\t\".join(map(str, scores))\n",
    "        handle.write(f\"filter{i}\\t{s}\\n\")\n",
    "\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead7cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779aaa75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
