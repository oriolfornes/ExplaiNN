{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cde3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "import click\n",
    "from click_option_group import optgroup\n",
    "import gc\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41502412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.architectures import CAM, NonStrandSpecific\n",
    "from utils.jaspar import get_figure, reformat_jaspar_motif\n",
    "from utils.sequence import one_hot_encode, one_hot_decode, rc_one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a52766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9254cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"../../results/TF-Binding-Matrix/CAM.cnn-units=16/TP53/best_model.pth.tar\"\n",
    "training_file = \"../../results/TF-Binding-Matrix/FASTA/Train/TP53.fa.gz\"\n",
    "batch_size = 2**6\n",
    "debugging = False\n",
    "output_dir = \"../../results/TF-Binding-Matrix/CAM.cnn-units=16/TP53/\"\n",
    "threads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eba866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dirs\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for subdir in [\"profiles\", \"logos\"]:\n",
    "    if not os.path.isdir(os.path.join(output_dir, subdir)):\n",
    "        os.makedirs(os.path.join(output_dir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f23bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_state_dict(state_dict):\n",
    "\n",
    "    for k in frozenset(state_dict.keys()):\n",
    "        state_dict[k[6:]] = state_dict.pop(k)\n",
    "\n",
    "    return(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69850c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAM(\n",
       "  (linears): Sequential(\n",
       "    (0): Conv1d(64, 16, kernel_size=(26,), stride=(1,), groups=16)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ExpAct()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): UnSqueeze()\n",
       "    (6): Conv1d(400, 1600, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (7): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.3, inplace=False)\n",
       "    (10): Conv1d(1600, 16, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (11): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (final): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "selene_dict = torch.load(model_file)\n",
    "model = CAM(\n",
    "    selene_dict[\"options\"][\"cnn_units\"],\n",
    "    selene_dict[\"options\"][\"motif_length\"],\n",
    "    selene_dict[\"options\"][\"sequence_length\"],\n",
    "    selene_dict[\"options\"][\"n_features\"],\n",
    "    selene_dict[\"options\"][\"input_data\"],\n",
    "    selene_dict[\"options\"][\"weights_file\"],\n",
    ")\n",
    "try:\n",
    "    model.load_state_dict(selene_dict[\"state_dict\"])\n",
    "except:\n",
    "    model.load_state_dict(_fix_state_dict(selene_dict[\"state_dict\"]))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe340ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Xs_ys(fasta_file, debugging=False):\n",
    "\n",
    "    # Initialize\n",
    "    Xs = []\n",
    "    ys = []\n",
    "\n",
    "    # Xs / ys\n",
    "    handle = _get_handle(fasta_file)\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        _, y_list = record.description.split()\n",
    "        Xs.append(one_hot_encode(str(record.seq).upper()))\n",
    "        ys.append([float(y) for y in y_list.split(\";\")])\n",
    "\n",
    "    if debugging:\n",
    "        return(np.array(Xs)[:10000], np.array(ys)[:10000])\n",
    "\n",
    "    return(np.array(Xs), np.array(ys))\n",
    "\n",
    "def _get_data_loader(Xs_train, ys_train, batch_size=2**6, threads=1):\n",
    "\n",
    "    # Reverse complement\n",
    "    n = len(Xs_train)\n",
    "    for i in range(n):\n",
    "        encoded_seq = rc_one_hot_encoding(Xs_train[i])\n",
    "        Xs_train.append(encoded_seq)\n",
    "        ys_train.append(ys_train[i])\n",
    "\n",
    "    # TensorDatasets\n",
    "    train_set = TensorDataset(torch.Tensor(Xs_train), torch.Tensor(ys_train))\n",
    "\n",
    "    # DataLoaders\n",
    "    kwargs = dict(batch_size=batch_size, num_workers=threads)\n",
    "    train_loader = DataLoader(train_set, **kwargs)\n",
    "\n",
    "    return(train_loader)\n",
    "\n",
    "def _get_handle(file_name):\n",
    "    if file_name.endswith(\"gz\"):\n",
    "        handle = gzip.open(file_name, \"rt\")\n",
    "    else:\n",
    "        handle = open(file_name, \"rt\")\n",
    "    return(handle)\n",
    "\n",
    "def _release_memory(my_object):\n",
    "   del my_object\n",
    "   gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4df12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Xs/ys\n",
    "Xs, ys = _get_Xs_ys(training_file, debugging)\n",
    "\n",
    "# Get DataLoader\n",
    "data_loader = _get_data_loader(list(Xs), list(ys), batch_size, threads)\n",
    "\n",
    "# Free up memory\n",
    "_release_memory(Xs)\n",
    "_release_memory(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab8dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_activations(model, data_loader):\n",
    "\n",
    "    # Initialize\n",
    "    activations = torch.tensor([], dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(data_loader, total=len(data_loader)):\n",
    "            x = x.to(device)\n",
    "            x = x.repeat(1, model._options[\"cnn_units\"], 1)\n",
    "            activation = model.linears[:3](x)\n",
    "            activations = torch.cat([activations, activation.cpu()])\n",
    "\n",
    "    return(activations.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16785ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_pfms(sequences, activations, motif_length=19):\n",
    "\n",
    "    \"\"\"\n",
    "    For each filter, build a Position Frequency Matrix (PFM) from all sites\n",
    "    reaching at least Â½ the maximum activation value for that filter across all input sequences\n",
    "    \n",
    "     the\n",
    "    activations and the original sequences, and keep the sites used to\n",
    "    derive such matrix.\n",
    "\n",
    "    params :\n",
    "        actvations (np.array) : (N*N_filters*L) array containing the ourput for each filter and selected sequence of the test set\n",
    "        sequnces (np.array) : (N*4*200) selected sequences (ACGT)\n",
    "        y (np.array) : (N*T) original target of the selected sequnces\n",
    "        output_file_path (str) : path to directory to store the resulting pwm meme file\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    n_filters = activations.shape[1]\n",
    "    pfms = np.zeros((n_filters, 4, motif_length))\n",
    "    # sites = [[] for _ in range(n_filters)]\n",
    "\n",
    "    # Find the threshold value for activations (i.e. 50%)\n",
    "    activation_thresholds = 0.5*np.amax(activations, axis=(0, 2))\n",
    "\n",
    "    # For each filter...\n",
    "    for i in range(n_filters):\n",
    "\n",
    "        activated_sequences_list = []\n",
    "\n",
    "        # For each sequence...\n",
    "        for j in range(len(sequences)):\n",
    "\n",
    "            # Get indices of sequences that activate the filter\n",
    "            idx = np.where(activations[j,i,:] > activation_thresholds[i])\n",
    "\n",
    "            for ix in idx[0]:\n",
    "\n",
    "                s = sequences[j][:,ix:ix+motif_length]\n",
    "                # activated_sequences_list.append(s)\n",
    "\n",
    "                # Build PFM\n",
    "                pfms[i] = np.add(pfms[i], s)\n",
    "\n",
    "        # # If activated sequences...\n",
    "        # if activated_sequences_list:\n",
    "\n",
    "        #     # Convert activated sequences to array\n",
    "        #     activated_sequences_arr = np.stack(activated_sequences_list)\n",
    "\n",
    "        #     # Build PFM\n",
    "        #     pfms[i] = np.sum(activated_sequences_arr, axis=0)\n",
    "\n",
    "            # # Save sites that activated the filter\n",
    "            # for s in activated_sequences_list:\n",
    "            #     sites[i].append(one_hot_decode(s))\n",
    "\n",
    "    # return(pfms, sites)\n",
    "    return(pfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15222d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 85/85 [00:03<00:00, 22.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "outputs = []\n",
    "labels = []\n",
    "sequences = []\n",
    "profiles = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, label in tqdm(data_loader, total=len(data_loader)):\n",
    "        for encoded_seq in x:\n",
    "            sequence = \"N\" * model._options[\"motif_length\"]\n",
    "            sequence += one_hot_decode(encoded_seq.numpy())\n",
    "            sequence += \"N\" * model._options[\"motif_length\"]\n",
    "            sequences.append(one_hot_encode(sequence))\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        if model._options[\"input_data\"] == \"binary\":\n",
    "            out = torch.sigmoid(out)\n",
    "        outputs.extend(out.detach().cpu().numpy())\n",
    "        labels.extend(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0511c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 85/85 [00:01<00:00, 80.66it/s] \n"
     ]
    }
   ],
   "source": [
    "# Get activations\n",
    "activations = __get_activations(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d2810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "_release_memory(data_loader)\n",
    "\n",
    "# Filter sequences/activations\n",
    "sequences = np.array(sequences)\n",
    "outputs = np.array(outputs)\n",
    "labels = np.array(labels)\n",
    "if model._options[\"input_data\"] == \"binary\":\n",
    "    ixs = np.where(labels == 1.)\n",
    "    sequences = sequences[ixs, :, :][0]\n",
    "    activations = activations[ixs, :, :][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0945b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Position Frequency Matrices (PFMs)\n",
    "pfms = __get_pfms(sequences, activations, model._options[\"motif_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd4b740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get profiles\n",
    "for j in range(len(pfms)):\n",
    "    handle = StringIO(\"\\n\".join([\"\\t\".join(map(str, i)) for i in pfms[j]]))\n",
    "    profiles.append(motifs.read(handle, \"pfm-four-rows\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d49eb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights\n",
    "weights = model.final.weight.detach().cpu().numpy().flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71faf856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2451865673065186,\n",
       " 0.0,\n",
       " 0.13975411653518677,\n",
       " 0.0,\n",
       " 1.3888148069381714,\n",
       " 1.2927360534667969,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.316008448600769,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3d631dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACATTTTTCAAGATATAAAATTTTA 1.2451865673065186\n",
      "CCCTGGGGTGGTTCTATTGAACAGTT 0.0\n",
      "AGTTTAAACAGGAGCTGAGACGAACC 0.13975411653518677\n",
      "AGATGGAAGAAAAAGGGAGGGAATGA 0.0\n",
      "TCTTTAAGAAATCTATTTTGTATTAC 1.3888148069381714\n",
      "GATATGAAAAACTACACAGGGGACAT 1.2927360534667969\n",
      "TTATAATAAGAAGTAAAATTAAAAAA 0.0\n",
      "CGTGATGGAACGTCGGTGCGGTTGGG 0.0\n",
      "GAGCTTTTCGAGATAGGCTAGCCCAG 0.0\n",
      "GGATGTTCTAATGGTGGGGAGTGGTA 0.0\n",
      "CATGTTCTGAAAGATTGATTAGTTTT 0.0\n",
      "GCAACCACGGAATATATCAAGTCTGT 0.0\n",
      "TATCCAGAGATGAAATATTCCACTGC 1.316008448600769\n",
      "GTGAGATTTTAAAGAACAGAGGTCTT 0.0\n",
      "AGGATACGCCGTGTGTGCCAGAGGGA 0.0\n",
      "TATGGAGATGGAAATAAGTCCGAACT 0.0\n"
     ]
    }
   ],
   "source": [
    "for z in zip(profiles, weights):\n",
    "    print(z[0].consensus, z[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ce5d863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[161., 164., 167., ..., 167., 162., 190.],\n",
       "        [162., 154., 177., ..., 149., 137., 184.],\n",
       "        [129., 134., 121., ..., 139., 151., 153.],\n",
       "        [158., 160., 148., ..., 204., 214., 139.]],\n",
       "\n",
       "       [[  0.,   0.,   0., ...,   2.,   0.,   0.],\n",
       "        [  2.,   2.,   2., ...,   0.,   1.,   0.],\n",
       "        [  0.,   0.,   0., ...,   2.,   1.,   0.],\n",
       "        [  1.,   1.,   1., ...,   0.,   2.,   4.]],\n",
       "\n",
       "       [[  5.,   3.,   2., ...,   5.,   2.,   1.],\n",
       "        [  3.,   1.,   4., ...,   4.,   7.,  10.],\n",
       "        [  2.,   7.,   2., ...,   3.,   1.,   2.],\n",
       "        [  4.,   3.,   6., ...,   4.,   6.,   3.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  1.,   5.,   5., ...,   4.,   5.,   4.],\n",
       "        [  4.,   1.,   2., ...,   7.,   1.,   5.],\n",
       "        [  5.,   2.,   5., ...,   3.,   2.,   4.],\n",
       "        [  4.,   6.,   3., ...,   2.,   9.,   5.]],\n",
       "\n",
       "       [[ 14.,  11.,  11., ...,  11.,  13.,  15.],\n",
       "        [ 11.,   7.,  11., ...,  11.,   6.,   9.],\n",
       "        [  9.,  15.,  11., ...,  12.,  14.,  11.],\n",
       "        [  7.,   8.,   8., ...,  10.,  11.,  10.]],\n",
       "\n",
       "       [[  7.,   8.,   5., ...,  10.,   8.,   5.],\n",
       "        [  5.,   6.,   3., ...,   9.,  10.,   9.],\n",
       "        [  6.,   4.,   8., ...,   5.,   7.,   8.],\n",
       "        [  8.,   8.,  10., ...,   8.,   7.,  10.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac5e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
