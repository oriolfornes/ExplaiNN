{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cde3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import click\n",
    "from click_option_group import optgroup\n",
    "import gc\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "bar_format = \"{percentage:3.0f}%|{bar:20}{r_bar}\"\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41502412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import CAM\n",
    "from jaspar import get_figure, reformat_motifs\n",
    "from sequence import one_hot_encode, rc_one_hot_encoding, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a52766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9254cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_file = \"../results/SMS.published/CAM/CTCF.NA@snappy-grey-markhor/best_model.pth.tar\"\n",
    "#training_file = \"../results/SMS.published/FASTA/Train/CTCF.NA@snappy-grey-markhor.fa.gz\"\n",
    "#output_dir = \"../results/SMS.published/CAM/CTCF.NA@snappy-grey-markhor/\"\n",
    "#tf_name = \"SOX2.NA\"\n",
    "#model_file = \"../results/Human-Mouse-Project/CAM/best_model.pth.tar\"\n",
    "#training_file = \"../results/Human-Mouse-Project/FASTA/train.fa.gz\"\n",
    "#output_dir = \"../results/Human-Mouse-Project/CAM/\"\n",
    "#tf_name = \"human-mouse\"\n",
    "model_file = \"../results/IRF4/CAM/HT-SELEX/T95R/best_model.pth.tar\"\n",
    "training_file = \"../results/IRF4/FASTA/HT-SELEX/T95R.train.fa.gz\"\n",
    "output_dir = \"../results/IRF4/CAM/HT-SELEX/T95R/\"\n",
    "tf_name = \"T95R\"\n",
    "#model_file = \"../results/HTS/CAM/ZBED2.FL@greasy-alizarin-guppy+blurry-buff-tiger+sunny-azure-tang/best_model.pth.tar\"\n",
    "#training_file = \"../results/HTS/FASTA/Train/ZBED2.FL@greasy-alizarin-guppy+blurry-buff-tiger+sunny-azure-tang.fa.gz\"\n",
    "#output_dir = \"../results/HTS/CAM/ZBED2.FL@greasy-alizarin-guppy+blurry-buff-tiger+sunny-azure-tang/\"\n",
    "#tf_name = \"ZBED2.FL\"\n",
    "batch_size = 2**6\n",
    "debugging = False\n",
    "threads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eba866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dirs\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for subdir in [\"sites\", \"motifs\", \"logos\"]:\n",
    "    if not os.path.isdir(os.path.join(output_dir, subdir)):\n",
    "        os.makedirs(os.path.join(output_dir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f23bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAM(\n",
       "  (linears): Sequential(\n",
       "    (0): Conv1d(64, 16, kernel_size=(19,), stride=(1,), padding=(19,), groups=16)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ExpAct()\n",
       "    (3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): UnSqueeze()\n",
       "    (6): Conv1d(128, 1600, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (7): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.3, inplace=False)\n",
       "    (10): Conv1d(1600, 16, kernel_size=(1,), stride=(1,), groups=16)\n",
       "    (11): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (final): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "selene_dict = torch.load(model_file)\n",
    "model = CAM(\n",
    "    selene_dict[\"options\"][\"cnn_units\"],\n",
    "    selene_dict[\"options\"][\"kernel_size\"],\n",
    "    selene_dict[\"options\"][\"sequence_length\"],\n",
    "    selene_dict[\"options\"][\"n_features\"],\n",
    "    selene_dict[\"options\"][\"clamp_weights\"],\n",
    "    selene_dict[\"options\"][\"no_padding\"],\n",
    "    selene_dict[\"options\"][\"weights_file\"],\n",
    ")\n",
    "model.load_state_dict(selene_dict[\"state_dict\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13dfb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "if selene_dict[\"options\"][\"no_padding\"]:\n",
    "    padding = 0\n",
    "else:\n",
    "    padding = selene_dict[\"options\"][\"kernel_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe340ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Xs_ys_record_ids_sequences(fasta_file, debugging=False, reverse_complement=False):\n",
    "\n",
    "    # Initialize\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    record_ids = []\n",
    "    sequences = []\n",
    "\n",
    "    # Xs / ys\n",
    "    handle = __get_handle(fasta_file)\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        _, y_list = record.description.split()\n",
    "        Xs.append(one_hot_encode(str(record.seq).upper()))\n",
    "        ys.append([float(y) for y in y_list.split(\";\")])\n",
    "        record_ids.append((record.id, \"+\"))\n",
    "        sequences.append(str(record.seq))\n",
    "\n",
    "    # Reverse complement\n",
    "    if reverse_complement:\n",
    "        n = len(Xs)\n",
    "        for i in range(n):\n",
    "            Xs.append(rc_one_hot_encoding(Xs[i]))\n",
    "            ys.append(ys[i])\n",
    "            record_ids.append((record_ids[i][0], \"-\"))\n",
    "            sequences.append(rc(sequences[i]))\n",
    "\n",
    "    # Return 1,000 sequences\n",
    "    if debugging:\n",
    "        return(np.array(Xs)[:10000], np.array(ys)[:10000], \n",
    "               np.array(record_ids)[:10000])\n",
    "\n",
    "    return(np.array(Xs), np.array(ys), np.array(record_ids), sequences)\n",
    "\n",
    "def _get_data_loader(Xs_train, ys_train, batch_size=2**6, threads=1):\n",
    "\n",
    "    # TensorDatasets\n",
    "    train_set = TensorDataset(torch.Tensor(Xs_train), torch.Tensor(ys_train))\n",
    "\n",
    "    # DataLoaders\n",
    "    kwargs = dict(batch_size=batch_size, num_workers=threads)\n",
    "    train_loader = DataLoader(train_set, **kwargs)\n",
    "\n",
    "    return(train_loader)\n",
    "\n",
    "def __get_handle(file_name):\n",
    "    if file_name.endswith(\"gz\"):\n",
    "        handle = gzip.open(file_name, \"rt\")\n",
    "    else:\n",
    "        handle = open(file_name, \"rt\")\n",
    "    return(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Xs/ys/record ids\n",
    "Xs, ys, record_ids, sequences = _get_Xs_ys_record_ids_sequences(training_file, debugging, True)\n",
    "\n",
    "# Get DataLoader\n",
    "data_loader = _get_data_loader(list(Xs), list(ys), batch_size, threads)\n",
    "\n",
    "# Input data\n",
    "if np.unique(ys[:, 0]).size == 2:\n",
    "    input_data = \"binary\"\n",
    "else:\n",
    "    input_data = \"linear\"\n",
    "\n",
    "# Fix sequences\n",
    "for i in range(len(sequences)):\n",
    "    sequences[i] = \"N\" * padding + sequences[i] + \"N\" * padding\n",
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16930941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free memory\n",
    "del Xs\n",
    "del ys\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15222d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3022/14138 [00:09<00:36, 307.81it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/storage.py\", line 135, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: unable to open shared memory object </torch_4584_1340488942> in read-write mode\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-957049c974ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get sequences, outputs, and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Get outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/mnt/md1/home/oriol/.conda/envs/jmodisco/lib/python3.6/site-packages/torch/storage.py\", line 135, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: unable to open shared memory object </torch_4584_1340488942> in read-write mode\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "# Get sequences, outputs, and labels\n",
    "with torch.no_grad():\n",
    "    for x, label in tqdm(iter(data_loader), total=len(data_loader)):\n",
    "\n",
    "        # Get outputs\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        if input_data == \"binary\":\n",
    "            out = torch.sigmoid(out)\n",
    "        outputs.extend(out.detach().cpu().numpy())\n",
    "\n",
    "        # Get labels\n",
    "        labels.extend(label.numpy())\n",
    "\n",
    "# To NumPy\n",
    "outputs = np.array(outputs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_activations(model, data_loader, activations):\n",
    "\n",
    "    # Counter\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(data_loader, total=len(data_loader)):\n",
    "            x = x.to(device)\n",
    "            x = x.repeat(1, model._options[\"cnn_units\"], 1)\n",
    "            activations[idx:idx+x.shape[0], :, :] = model.linears[:3](x).cpu()\n",
    "            idx += x.shape[0]           \n",
    "\n",
    "    return(activations.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0511c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations\n",
    "shape = (len(sequences), model._options[\"cnn_units\"], len(sequences[0]) - model._options[\"kernel_size\"] + 1)\n",
    "activations = __get_activations(model, iter(data_loader), torch.zeros(shape, dtype=torch.float32))\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of well predicted sequences\n",
    "if input_data == \"binary\":\n",
    "    indices = np.where((labels == 1.) & (outputs >= .5))[0]\n",
    "else:\n",
    "    labels_ixs = np.argsort(-labels.flatten())[:int(max(labels.shape) * .1)]\n",
    "    outputs_ixs = np.argsort(-outputs.flatten())[:int(max(outputs.shape) * .1)]\n",
    "    indices = np.intersect1d(labels_ixs, outputs_ixs)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "del labels\n",
    "del outputs\n",
    "del data_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter, get the activation thresholds (i.e. ≥50%)\n",
    "act_thresholds = 0.5 * np.amax(activations[indices, :, :], axis=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16785ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_filter_sites(indices, record_ids, sequences, activations,\n",
    "                       threshold, kernel_size=19):\n",
    "    \"\"\"\n",
    "    For each filter and for each sequence, get sites reaching at least\n",
    "    ½ of the maximum activation value for that filter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    sites = []\n",
    "\n",
    "    # For each sequence...\n",
    "    for i in indices:\n",
    "\n",
    "        # Get start positions of sequence sites activating this filter\n",
    "        starts = np.where(activations[i, :] > threshold)\n",
    "\n",
    "        # For each start...\n",
    "        for j in starts[0]:\n",
    "\n",
    "            # Get site\n",
    "            seq = Seq(sequences[i][j:j+kernel_size])\n",
    "            seq_id = \"%s_%s_from=%s_to=%s\" % (record_ids[i][0],\n",
    "                                              record_ids[i][1],\n",
    "                                              j, j+kernel_size)\n",
    "            sites.append(SeqRecord(seq, id=seq_id, name=\"\",\n",
    "                                   description=\"\"))\n",
    "\n",
    "    return(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae102e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each filter...\n",
    "for i in tqdm(range(selene_dict[\"options\"][\"cnn_units\"]), total=selene_dict[\"options\"][\"cnn_units\"]):\n",
    "\n",
    "    sites_file = os.path.join(output_dir, \"sites\", f\"filter{i}.fa\")\n",
    "    if not os.path.exists(sites_file):\n",
    "\n",
    "        # Get sites\n",
    "        sites = __get_filter_sites(indices, record_ids, sequences,\n",
    "                                   activations[:, i, :], act_thresholds[i],\n",
    "                                   model._options[\"kernel_size\"])\n",
    "\n",
    "        # Save sites\n",
    "        with open(sites_file, \"w\") as handle:\n",
    "            SeqIO.write(sites, handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b92884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_motif_from_sites(sites_file):\n",
    "    \"\"\"\n",
    "    From https://github.com/biopython/biopython/blob/master/Bio/motifs/__init__.py\n",
    "    Read the motif from JASPAR .sites file.\n",
    "    \"\"\"\n",
    "    alphabet = \"ACGTN\"\n",
    "    instances = []\n",
    "    pfm = {}\n",
    "\n",
    "    with open(sites_file) as handle:\n",
    "        for line in handle:\n",
    "            if not line.startswith(\">\"):\n",
    "                break\n",
    "            # line contains the header \">....\"\n",
    "            # now read the actual sequence\n",
    "            line = next(handle)\n",
    "            instance = \"\"\n",
    "            for c in line.strip().upper():\n",
    "                if c == c.upper():\n",
    "                    instance += c\n",
    "            instance = Seq(instance)\n",
    "            instances.append(instance)\n",
    "\n",
    "    instances = motifs.Instances(instances, alphabet)\n",
    "    motif = motifs.Motif(alphabet=alphabet, instances=instances)\n",
    "\n",
    "    for nt in alphabet[:-1]:\n",
    "        pfm.setdefault(nt, motif.counts[nt])\n",
    "\n",
    "    return(motifs.Motif(counts=pfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0297c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "profiles = []\n",
    "\n",
    "# For each filter...\n",
    "for i in tqdm(range(selene_dict[\"options\"][\"cnn_units\"]), total=selene_dict[\"options\"][\"cnn_units\"]):\n",
    "\n",
    "    motif_file = os.path.join(output_dir, \"motifs\", f\"filter{i}.jaspar\")\n",
    "    if not os.path.exists(motif_file):\n",
    "\n",
    "        # Get motif\n",
    "        sites_file = os.path.join(output_dir, \"sites\", f\"filter{i}.fa\")\n",
    "        motif = __get_motif_from_sites(sites_file)\n",
    "        motif.matrix_id = f\"filter{i}\"\n",
    "        motif.name = tf_name\n",
    "\n",
    "        # Save motif\n",
    "        with open(motif_file, \"w\") as handle:\n",
    "            handle.write(format(motif, \"jaspar\"))\n",
    "\n",
    "    profiles.append(motifs.read(open(motif_file), \"jaspar\"))\n",
    "\n",
    "meme_file = os.path.join(output_dir, \"motifs\", \"filters.meme\")\n",
    "if not os.path.exists(meme_file):\n",
    "\n",
    "    # Reformat motif\n",
    "    reformat_motifs(profiles, \"meme\", meme_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7208912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/IRF4/CAM/HT-SELEX/T95R/motifs/filter0.jaspar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-242e41c6e421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmotif_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"motifs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"filter{i}.jaspar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotif_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/home/oriol/deep-motif-discovery/CAM/jaspar/jaspar2logo.py\u001b[0m in \u001b[0;36mget_figure\u001b[0;34m(motif_file, rc)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# From https://biopython.readthedocs.io/en/latest/chapter_motifs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmotifs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotif_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jaspar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpseudocounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"G\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/IRF4/CAM/HT-SELEX/T95R/motifs/filter0.jaspar'"
     ]
    }
   ],
   "source": [
    "# For each filter...\n",
    "for i in tqdm(range(selene_dict[\"options\"][\"cnn_units\"]), total=selene_dict[\"options\"][\"cnn_units\"]):\n",
    "\n",
    "    for rc in [False, True]:\n",
    "\n",
    "        if rc:\n",
    "            logo_file = os.path.join(output_dir, \"logos\", f\"filter{i}.rev.png\")\n",
    "        else:\n",
    "            logo_file = os.path.join(output_dir, \"logos\", f\"filter{i}.fwd.png\")\n",
    "\n",
    "        # Save logo\n",
    "        if not os.path.exists(logo_file):\n",
    "            motif_file = os.path.join(output_dir, \"motifs\", f\"filter{i}.jaspar\")\n",
    "            fig = get_figure(motif_file)\n",
    "            fig.savefig(logo_file, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d49eb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3528521 , -0.29451057,  0.30531645],\n",
       "       [-0.24405417, -0.23650311,  0.24233727],\n",
       "       [-0.20535707, -0.20170881,  0.2157277 ],\n",
       "       [-0.11448301, -0.17366448,  0.16967939],\n",
       "       [-0.2916462 , -0.24152793,  0.24980742],\n",
       "       [-0.4897612 , -0.29464194,  0.31356904],\n",
       "       [-0.44914818, -0.26849824,  0.28990597],\n",
       "       [-0.25040755, -0.2754214 ,  0.2824827 ],\n",
       "       [-0.24950728, -0.25231472,  0.26441914],\n",
       "       [-0.286229  , -0.34209013,  0.35273454],\n",
       "       [-0.31859136, -0.26678708,  0.27819097],\n",
       "       [-0.432877  , -0.23097682,  0.2400421 ],\n",
       "       [-0.2876617 , -0.14613852,  0.15665177],\n",
       "       [-0.47321957, -0.27279046,  0.29571202],\n",
       "       [-0.10455629, -0.07218737,  0.07642258],\n",
       "       [-0.4219171 , -0.2946628 ,  0.3085942 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get weights\n",
    "weights = model.final.weight.detach().cpu().numpy()\n",
    "weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71faf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "weights_file = os.path.join(output_dir, \"filter-weights.tsv\")\n",
    "if not os.path.exists(weights_file):\n",
    "    with open(weights_file, \"w\") as handle:\n",
    "        for i, weight in enumerate(weights.T):\n",
    "            s = \"\\t\".join(map(str, weight))\n",
    "            handle.write(f\"filter{i}\\t{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f25bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-choice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
